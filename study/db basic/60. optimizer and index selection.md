* optimizer and index selection
- if using index is inefficient, db don't use index

* index break-even point
- index usage cost: index search cost + data read by index cost(random i/o)
- full table scan cost: sequential i/o

normally for query about 20~25% data of table, sequential i/o is better than random i/o

* random i/o why slow?
- sequential i/o -> read book from 1 page
  - first, if stored position is found, read sequentially from that position 
  - hdd: disk head almost doesn't move, read sequentially quickly and efficiently
  - ssd: a single large command is executed once sequentially
- random i/o -> 
  - hdd: for read data, disk head have to move. need seek time every time. it is slower than sequential i/o
  - ssd: if data to read is 100 pieces, 100 pieces of small command are executed.

  
* example 1: efficient search using index
- idx_items_price -> select * from items where price between 50000 and 100000
- type: range

* example 2: inefficient search using index
- idx_items_price -> select * from items where price between 1000 and 200000
- type: ALL, possible_keys: idx_items_price, key: NULL, filtered: 76 -> full table scan
  - optimizer know possible_keys, but doesn't use it
  - filtered: 76 -> return 76% of data

* data size is too small
- optimizer could use full table scan