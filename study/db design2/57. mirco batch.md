* in a large-scale system, intraday stats can load db
- if order counts are a billion per day and real-time stats is needed
- micro-batch approach: batch job run every 5 minutes

* micro-batch design
1. intraday stats table creation
- intraday_sales_stats
```sql
drop table if exists intraday_sales_stats;

create table intraday_sales_stats(
    today_date date not null,
    total_order_count int not null default 0,
    total_sales_amount bigint not null default 0,
    updated_at datetime,
    primary key(today_date)
)
```
2. micro-batch job run(delete & insert strategy)

prepare
```sql
-- 실습용 데이터 삽입 (오늘이 2026-01-02라고 가정)
INSERT INTO orders (customer_id, total_amount, order_status, order_date) VALUES
(1, 50000, 'COMPLETED', '2026-01-02 10:00:00'),
(2, 30000, 'COMPLETED', '2026-01-02 11:30:00'),
(3, 120000, 'COMPLETED', '2026-01-02 12:15:00');
```

delete & insert
```sql
-- 1. 트랜잭션 시작
START TRANSACTION;

-- 2. 기존 오늘자(2026-01-02) 통계 삭제
DELETE FROM intraday_sales_stats WHERE today_date = '2026-01-02';

-- 3. 오늘자 통계 다시 계산해서 입력
INSERT INTO intraday_sales_stats (today_date, total_order_count, total_sales_amount, updated_at)
SELECT
  DATE(order_date),
  COUNT(*),
  SUM(total_amount),
  '2026-01-02 13:05:00' -- NOW()를 사용해야 하지만, 예시를 위해 시간 지정
FROM orders
WHERE order_date >= '2026-01-02' AND order_date < '2026-01-03' -- 오늘 데이터 선택
 AND order_status = 'COMPLETED'
GROUP BY DATE(order_date);

-- 4. 커밋
COMMIT;
```

3. stats query changed: using daily_sales_stats, intraday_sales_stats
```sql
SELECT
    stat_date,
    total_order_count,
    total_sales_amount
FROM daily_sales_stats
WHERE stat_date >= '2026-01-01' -- 조회 기간 시작

UNION ALL

SELECT
    today_date as stat_date,
    total_order_count,
    total_sales_amount
FROM intraday_sales_stats
WHERE today_date = '2026-01-02'; -- 오늘 데이터
```

* pros and cons
pros
- extreme query performance
- db resource usage is reduced: only a micro-batch job runs every 5 minutes
cons
- real-time latency: 5-minute delay
- implementation complexity: scheduler, table creation

* problem of delete & insert strategy in micro-batch
a micro-batch job run frequently
1. unnecessary resource usage
- delete make undo log and update index
- insert make redo log and update index
2. id depletion and index fragmentation
- auto_increment id is used
- frequent delete & insert can cause data page fragmentation

